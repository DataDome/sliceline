{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed55269",
   "metadata": {},
   "source": [
    "# End-to-end Sliceline application\n",
    "\n",
    "_____________________________\n",
    "This demo notebook is split in 2 parts:\n",
    "\n",
    "- **Machine Learning modelling**\n",
    "\n",
    "This part implements a basic classification pipeline on the [Titanic dataset](https://www.openml.org/search?type=data&sort=runs&id=40945&status=active) to predict if a passanger survived.\n",
    "\n",
    "- **Model debugging with Sliceline**\n",
    "\n",
    "This part identifies slices where the training error of the model is significantly higher, thanks to [sliceline](https://github.com/DataDome/sliceline).\n",
    "\n",
    "## Machine Learning modelling\n",
    "\n",
    "The pipeline is composed of 2 steps:\n",
    "1. The preprocessor: to transform raw data into numerical data without NaN,\n",
    "2. The classifier: a [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) with default parameters.\n",
    "\n",
    "The training error is the element-wise [log loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86620d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T08:52:04.294146Z",
     "start_time": "2022-09-01T08:52:03.399638Z"
    }
   },
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# fetch titanic dataset\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X.drop(['cabin', 'boat', 'body', 'home.dest', 'name', 'ticket'], axis=1, inplace=True)\n",
    "\n",
    "# define pipeline\n",
    "cat_cols = X.select_dtypes(\"category\").columns\n",
    "num_cols = X.select_dtypes(\"number\").columns\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "])\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols),\n",
    "    ])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# training\n",
    "clf.fit(X, y)\n",
    "\n",
    "# predict on training data\n",
    "y_proba = clf.predict_proba(X)[:, 1] # score of being a '1'\n",
    "\n",
    "# compute element-wise log loss (the lower, the better)\n",
    "eps = 1e-15\n",
    "y_proba = np.clip(y_proba, eps, 1 - eps)\n",
    "y = y.astype(int)\n",
    "\n",
    "training_errors = - (y * np.log(y_proba) + (1 - y) * np.log(1 - y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4ffe1",
   "metadata": {},
   "source": [
    "## Model debbuging with Sliceline\n",
    "\n",
    "**Sliceline considers all the columns of the input dataset as categorical.**\n",
    "\n",
    "So, to get more relevant slices, the following numerical features should be discretized:\n",
    "- `age`\n",
    "- `fare`\n",
    "\n",
    "Indeed, those columns as-is would lead to poor exploitable results. We would rather have range of values to specific value in our slices definition.\n",
    "\n",
    "To discretize them and compute their bins, we use [OptBinning](http://gnpalencia.org/optbinning/) but feel free to experiment other binning implementations.\n",
    "\n",
    "Sliceline configuration:\n",
    "- `alpha = 0.95`: we are interested in small slice with high log loss.\n",
    "- `k = 1`: we want Sliceline to find the rules with the best score.\n",
    "- `max_l = X_trans.shape[1]`: we want Sliceline to be able to use all of the inputs columns.\n",
    "- `min_sup = 1`: because the input dataset is relatively small, we do not add constraint regarding the minimal support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84583439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T08:52:37.350437Z",
     "start_time": "2022-09-01T08:52:04.296725Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:sliceline.slicefinder:Dropping 0/38 features below min_sup = 1.\n",
      "DEBUG:sliceline.slicefinder:Initial top-K: count=1, max=0.413802, min=0.413802\n",
      "DEBUG:sliceline.slicefinder:Level 2:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 38 -> 451\n",
      "/Users/antoinededaran/Documents/internal-sliceline/sliceline/slicefinder.py:332: RuntimeWarning: invalid value encountered in divide\n",
      "  (slice_errors / slice_sizes) / self.average_error_ - 1\n",
      "/Users/antoinededaran/Documents/internal-sliceline/sliceline/slicefinder.py:333: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) - (1 - self.alpha) * (n_row_x_encoded / slice_sizes - 1)\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 410/451\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=1, max=0.565950, min=0.565950\n",
      "DEBUG:sliceline.slicefinder:Level 3:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 451 -> 2282\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 2237/2282\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=1, max=0.682603, min=0.682603\n",
      "DEBUG:sliceline.slicefinder:Level 4:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 2282 -> 6396\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 6325/6396\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=2, max=0.705890, min=0.705890\n",
      "DEBUG:sliceline.slicefinder:Level 5:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 6396 -> 10255\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 10212/10255\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=9, max=0.705890, min=0.705890\n",
      "DEBUG:sliceline.slicefinder:Level 6:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 10255 -> 10197\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 10187/10197\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=14, max=0.705890, min=0.705890\n",
      "DEBUG:sliceline.slicefinder:Level 7:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 10197 -> 6448\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 6448/6448\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=15, max=0.705890, min=0.705890\n",
      "DEBUG:sliceline.slicefinder:Level 8:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 6448 -> 2555\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 2555/2555\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=15, max=0.705890, min=0.705890\n",
      "DEBUG:sliceline.slicefinder:Level 9:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 2555 -> 584\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 584/584\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=15, max=0.705890, min=0.705890\n",
      "DEBUG:sliceline.slicefinder:Level 10:\n",
      "DEBUG:sliceline.slicefinder: -- generated paired slice candidates: 584 -> 59\n",
      "DEBUG:sliceline.slicefinder: -- valid slices after eval: 59/59\n",
      "DEBUG:sliceline.slicefinder: -- top-K: count=15, max=0.705890, min=0.705890\n",
      "DEBUG:sliceline.slicefinder:Terminated at level 10.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Slicefinder(alpha=0.95, max_l=10, min_sup=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Slicefinder</label><div class=\"sk-toggleable__content\"><pre>Slicefinder(alpha=0.95, max_l=10, min_sup=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Slicefinder(alpha=0.95, max_l=10, min_sup=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sliceline and binning class\n",
    "from sliceline.slicefinder import Slicefinder\n",
    "from optbinning import ContinuousOptimalBinning\n",
    "\n",
    "# dataset before prediction\n",
    "X_trans = pd.DataFrame(clf[0].transform(X), columns=clf[0].get_feature_names_out())\n",
    "\n",
    "# `age` and `fare` have to be bined\n",
    "columns_to_bin = [\"num__age\", \"num__fare\"]\n",
    "\n",
    "optimal_binner = ContinuousOptimalBinning()\n",
    "\n",
    "X_trans[columns_to_bin] = np.array(\n",
    "    [\n",
    "        optimal_binner.fit_transform(X_trans[col], training_errors, metric=\"bins\") for col in columns_to_bin\n",
    "    ]\n",
    ").T\n",
    "\n",
    "# fitting sliceline\n",
    "sf = Slicefinder(\n",
    "    alpha = 0.95,\n",
    "    k = 1,\n",
    "    max_l = X_trans.shape[1],\n",
    "    min_sup = 1,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "sf.fit(X_trans, training_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e08e0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T08:52:37.366306Z",
     "start_time": "2022-09-01T08:52:37.352172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__pclass</th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__sibsp</th>\n",
       "      <th>num__parch</th>\n",
       "      <th>num__fare</th>\n",
       "      <th>cat__sex_female</th>\n",
       "      <th>cat__sex_male</th>\n",
       "      <th>cat__embarked_C</th>\n",
       "      <th>cat__embarked_Q</th>\n",
       "      <th>cat__embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slice_0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slice_14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[39.50, inf)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num__pclass      num__age num__sibsp num__parch num__fare  \\\n",
       "slice_0          3.0  [39.50, inf)       None        0.0      None   \n",
       "slice_1          3.0  [39.50, inf)        0.0       None      None   \n",
       "slice_2          3.0  [39.50, inf)       None        0.0      None   \n",
       "slice_3          3.0  [39.50, inf)       None        0.0      None   \n",
       "slice_4          3.0  [39.50, inf)       None        0.0      None   \n",
       "slice_5          3.0  [39.50, inf)        0.0       None      None   \n",
       "slice_6          3.0  [39.50, inf)        0.0       None      None   \n",
       "slice_7          3.0  [39.50, inf)        0.0       None      None   \n",
       "slice_8          3.0  [39.50, inf)        0.0        0.0      None   \n",
       "slice_9          3.0  [39.50, inf)       None        0.0      None   \n",
       "slice_10         3.0  [39.50, inf)        0.0       None      None   \n",
       "slice_11         3.0  [39.50, inf)        0.0        0.0      None   \n",
       "slice_12         3.0  [39.50, inf)        0.0        0.0      None   \n",
       "slice_13         3.0  [39.50, inf)        0.0        0.0      None   \n",
       "slice_14         3.0  [39.50, inf)        0.0        0.0      None   \n",
       "\n",
       "         cat__sex_female cat__sex_male cat__embarked_C cat__embarked_Q  \\\n",
       "slice_0             None          None            None             1.0   \n",
       "slice_1             None          None            None             1.0   \n",
       "slice_2             None          None            None             1.0   \n",
       "slice_3             None          None             0.0            None   \n",
       "slice_4             None          None             0.0             1.0   \n",
       "slice_5             None          None            None             1.0   \n",
       "slice_6             None          None             0.0            None   \n",
       "slice_7             None          None             0.0             1.0   \n",
       "slice_8             None          None            None             1.0   \n",
       "slice_9             None          None             0.0             1.0   \n",
       "slice_10            None          None             0.0             1.0   \n",
       "slice_11            None          None            None             1.0   \n",
       "slice_12            None          None             0.0            None   \n",
       "slice_13            None          None             0.0             1.0   \n",
       "slice_14            None          None             0.0             1.0   \n",
       "\n",
       "         cat__embarked_S  \n",
       "slice_0             None  \n",
       "slice_1             None  \n",
       "slice_2              0.0  \n",
       "slice_3              0.0  \n",
       "slice_4             None  \n",
       "slice_5              0.0  \n",
       "slice_6              0.0  \n",
       "slice_7             None  \n",
       "slice_8             None  \n",
       "slice_9              0.0  \n",
       "slice_10             0.0  \n",
       "slice_11             0.0  \n",
       "slice_12             0.0  \n",
       "slice_13            None  \n",
       "slice_14             0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slices found\n",
    "pd.DataFrame(sf.top_slices_, columns=sf.feature_names_in_, index=sf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be72623",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "We found 15 slices with `k` set to 1. As described in the documentation, it means that those 15 slices have the same score.\n",
    "\n",
    "**In fact, they target the same subset of data.**\n",
    "\n",
    "_(`None` values refer to unused features in each slices.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8e3ea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T08:52:37.745108Z",
     "start_time": "2022-09-01T08:52:37.370418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model log loss on:\n",
      "- the full dataset (1309 passengers): 0.14262975213717055\n",
      "- the selected slice (38 passengers): 0.49969327000130753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# select one slice\n",
    "slice_index = 0\n",
    "current_slice = sf.top_slices_[slice_index]\n",
    "\n",
    "# create a pandas filter\n",
    "predicate_conditions = [X_trans[feature_name] == feature_value for feature_name, feature_value in zip(\n",
    "    sf.feature_names_in_, current_slice) if feature_value is not None]\n",
    "condition = \" & \".join(\n",
    "    [f\"@predicate_conditions[{i}]\" for i in range(len(predicate_conditions))]\n",
    ")\n",
    "\n",
    "# get slice element indices\n",
    "indices = X_trans.query(condition).index\n",
    "\n",
    "print(\"Model log loss on:\")\n",
    "print(f\"- the full dataset ({X.shape[0]} passengers):\", log_loss(y, y_proba))\n",
    "print(f\"- the selected slice ({len(indices)} passengers):\", log_loss(y.iloc[indices], y_proba[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812765cd",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "With Sliceline, we identified a subset of 38 passengers on which the model performs significantly worse. Those passengers:\n",
    "- were in 3rd class (`num__pclass=3`),\n",
    "- were 39.5 years old or more (`num__age='[39.50, inf)'`),\n",
    "- without any parents or children aboard (`num__parch=0.0`),\n",
    "- and embarked in Queenstown (`cat__embarked_Q=1`).\n",
    "\n",
    "To improve the modelisation, we should focus on reducing the error on those passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c752fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
